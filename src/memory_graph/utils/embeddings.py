"""
åµŒå…¥å‘é‡ç”Ÿæˆå™¨ï¼šä¼˜å…ˆä½¿ç”¨é…ç½®çš„ embedding APIï¼Œsentence-transformers ä½œä¸ºå¤‡é€‰
"""

from __future__ import annotations

import asyncio

import numpy as np

from src.common.logger import get_logger

logger = get_logger(__name__)


class EmbeddingGenerator:
    """
    åµŒå…¥å‘é‡ç”Ÿæˆå™¨

    ç­–ç•¥ï¼š
    1. ä¼˜å…ˆä½¿ç”¨é…ç½®çš„ embedding APIï¼ˆé€šè¿‡ LLMRequestï¼‰
    2. å¦‚æœ API ä¸å¯ç”¨ï¼Œå›é€€åˆ°æœ¬åœ° sentence-transformers
    3. å¦‚æœ sentence-transformers æœªå®‰è£…ï¼Œä½¿ç”¨éšæœºå‘é‡ï¼ˆä»…æµ‹è¯•ï¼‰

    ä¼˜ç‚¹ï¼š
    - é™ä½æœ¬åœ°è¿ç®—è´Ÿè½½
    - å³ä½¿æœªå®‰è£… sentence-transformers ä¹Ÿå¯æ­£å¸¸è¿è¡Œ
    - ä¿æŒä¸ç°æœ‰ç³»ç»Ÿçš„ä¸€è‡´æ€§
    """

    def __init__(
        self,
        use_api: bool = True,
        fallback_model_name: str = "paraphrase-multilingual-MiniLM-L12-v2",
    ):
        """
        åˆå§‹åŒ–åµŒå…¥ç”Ÿæˆå™¨

        Args:
            use_api: æ˜¯å¦ä¼˜å…ˆä½¿ç”¨ APIï¼ˆé»˜è®¤ Trueï¼‰
            fallback_model_name: å›é€€æœ¬åœ°æ¨¡å‹åç§°
        """
        self.use_api = use_api
        self.fallback_model_name = fallback_model_name

        # API ç›¸å…³
        self._llm_request = None
        self._api_available = False
        self._api_dimension = None

        # æœ¬åœ°æ¨¡å‹ç›¸å…³
        self._local_model = None
        self._local_model_loaded = False

    async def _initialize_api(self):
        """åˆå§‹åŒ– embedding API"""
        if self._api_available:
            return

        try:
            from src.config.config import model_config
            from src.llm_models.utils_model import LLMRequest

            embedding_config = model_config.model_task_config.embedding
            self._llm_request = LLMRequest(
                model_set=embedding_config,
                request_type="memory_graph.embedding"
            )

            # è·å–åµŒå…¥ç»´åº¦
            if hasattr(embedding_config, "embedding_dimension") and embedding_config.embedding_dimension:
                self._api_dimension = embedding_config.embedding_dimension

            self._api_available = True
            logger.info(f"âœ… Embedding API åˆå§‹åŒ–æˆåŠŸ (ç»´åº¦: {self._api_dimension})")

        except Exception as e:
            logger.warning(f"âš ï¸  Embedding API åˆå§‹åŒ–å¤±è´¥: {e}")
            self._api_available = False

    def _load_local_model(self):
        """å»¶è¿ŸåŠ è½½æœ¬åœ°æ¨¡å‹"""
        if not self._local_model_loaded:
            try:
                from sentence_transformers import SentenceTransformer

                logger.info(f"ğŸ“¦ åŠ è½½æœ¬åœ°åµŒå…¥æ¨¡å‹: {self.fallback_model_name}")
                self._local_model = SentenceTransformer(self.fallback_model_name)
                self._local_model_loaded = True
                logger.info("âœ… æœ¬åœ°åµŒå…¥æ¨¡å‹åŠ è½½æˆåŠŸ")
            except ImportError:
                logger.warning(
                    "âš ï¸  sentence-transformers æœªå®‰è£…ï¼Œå°†ä½¿ç”¨éšæœºå‘é‡ï¼ˆä»…æµ‹è¯•ç”¨ï¼‰\n"
                    "   å®‰è£…æ–¹æ³•: pip install sentence-transformers"
                )
                self._local_model_loaded = False
            except Exception as e:
                logger.warning(f"âš ï¸  æœ¬åœ°æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                self._local_model_loaded = False

    async def generate(self, text: str) -> np.ndarray:
        """
        ç”Ÿæˆå•ä¸ªæ–‡æœ¬çš„åµŒå…¥å‘é‡

        ç­–ç•¥ï¼š
        1. ä¼˜å…ˆä½¿ç”¨ API
        2. API å¤±è´¥åˆ™ä½¿ç”¨æœ¬åœ°æ¨¡å‹
        3. æœ¬åœ°æ¨¡å‹ä¸å¯ç”¨åˆ™ä½¿ç”¨éšæœºå‘é‡

        Args:
            text: è¾“å…¥æ–‡æœ¬

        Returns:
            åµŒå…¥å‘é‡
        """
        if not text or not text.strip():
            logger.warning("è¾“å…¥æ–‡æœ¬ä¸ºç©ºï¼Œè¿”å›é›¶å‘é‡")
            dim = self._get_dimension()
            return np.zeros(dim, dtype=np.float32)

        try:
            # ç­–ç•¥ 1: ä½¿ç”¨ API
            if self.use_api:
                embedding = await self._generate_with_api(text)
                if embedding is not None:
                    return embedding

            # ç­–ç•¥ 2: ä½¿ç”¨æœ¬åœ°æ¨¡å‹
            embedding = await self._generate_with_local_model(text)
            if embedding is not None:
                return embedding

            # ç­–ç•¥ 3: éšæœºå‘é‡ï¼ˆä»…æµ‹è¯•ï¼‰
            logger.warning(f"âš ï¸  æ‰€æœ‰åµŒå…¥ç­–ç•¥å¤±è´¥ï¼Œä½¿ç”¨éšæœºå‘é‡: {text[:30]}...")
            dim = self._get_dimension()
            return np.random.rand(dim).astype(np.float32)

        except Exception as e:
            logger.error(f"âŒ åµŒå…¥ç”Ÿæˆå¤±è´¥: {e}", exc_info=True)
            dim = self._get_dimension()
            return np.random.rand(dim).astype(np.float32)

    async def _generate_with_api(self, text: str) -> np.ndarray | None:
        """ä½¿ç”¨ API ç”ŸæˆåµŒå…¥"""
        try:
            # åˆå§‹åŒ– API
            if not self._api_available:
                await self._initialize_api()

            if not self._api_available or not self._llm_request:
                return None

            # è°ƒç”¨ API
            embedding_list, model_name = await self._llm_request.get_embedding(text)

            if embedding_list and len(embedding_list) > 0:
                embedding = np.array(embedding_list, dtype=np.float32)
                logger.debug(f"ğŸŒ API ç”ŸæˆåµŒå…¥: {text[:30]}... -> {len(embedding)}ç»´ (æ¨¡å‹: {model_name})")
                return embedding

            return None

        except Exception as e:
            logger.debug(f"API åµŒå…¥ç”Ÿæˆå¤±è´¥: {e}")
            return None

    async def _generate_with_local_model(self, text: str) -> np.ndarray | None:
        """ä½¿ç”¨æœ¬åœ°æ¨¡å‹ç”ŸæˆåµŒå…¥"""
        try:
            # åŠ è½½æœ¬åœ°æ¨¡å‹
            if not self._local_model_loaded:
                self._load_local_model()

            if not self._local_model_loaded or not self._local_model:
                return None

            # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œ
            loop = asyncio.get_event_loop()
            embedding = await loop.run_in_executor(None, self._encode_single_local, text)

            logger.debug(f"ğŸ’» æœ¬åœ°ç”ŸæˆåµŒå…¥: {text[:30]}... -> {len(embedding)}ç»´")
            return embedding

        except Exception as e:
            logger.debug(f"æœ¬åœ°æ¨¡å‹åµŒå…¥ç”Ÿæˆå¤±è´¥: {e}")
            return None

    def _encode_single_local(self, text: str) -> np.ndarray:
        """åŒæ­¥ç¼–ç å•ä¸ªæ–‡æœ¬ï¼ˆæœ¬åœ°æ¨¡å‹ï¼‰"""
        if self._local_model is None:
            raise RuntimeError("æœ¬åœ°æ¨¡å‹æœªåŠ è½½")
        embedding = self._local_model.encode(text, convert_to_numpy=True)  # type: ignore
        return embedding.astype(np.float32)

    def _get_dimension(self) -> int:
        """è·å–åµŒå…¥ç»´åº¦"""
        # ä¼˜å…ˆä½¿ç”¨ API ç»´åº¦
        if self._api_dimension:
            return self._api_dimension

        # å…¶æ¬¡ä½¿ç”¨æœ¬åœ°æ¨¡å‹ç»´åº¦
        if self._local_model_loaded and self._local_model:
            try:
                return self._local_model.get_sentence_embedding_dimension()
            except Exception:
                pass

        # é»˜è®¤ 384ï¼ˆsentence-transformers å¸¸ç”¨ç»´åº¦ï¼‰
        return 384

    async def generate_batch(self, texts: list[str]) -> list[np.ndarray]:
        """
        æ‰¹é‡ç”ŸæˆåµŒå…¥å‘é‡

        Args:
            texts: æ–‡æœ¬åˆ—è¡¨

        Returns:
            åµŒå…¥å‘é‡åˆ—è¡¨
        """
        if not texts:
            return []

        try:
            # è¿‡æ»¤ç©ºæ–‡æœ¬
            valid_texts = [t for t in texts if t and t.strip()]
            if not valid_texts:
                logger.warning("æ‰€æœ‰æ–‡æœ¬ä¸ºç©ºï¼Œè¿”å›é›¶å‘é‡åˆ—è¡¨")
                dim = self._get_dimension()
                return [np.zeros(dim, dtype=np.float32) for _ in texts]

            # ä½¿ç”¨ API æ‰¹é‡ç”Ÿæˆï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.use_api:
                results = await self._generate_batch_with_api(valid_texts)
                if results:
                    return results

            # å›é€€åˆ°é€ä¸ªç”Ÿæˆ
            results = []
            for text in valid_texts:
                embedding = await self.generate(text)
                results.append(embedding)

            logger.info(f"âœ… æ‰¹é‡ç”ŸæˆåµŒå…¥: {len(texts)} ä¸ªæ–‡æœ¬")
            return results

        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡åµŒå…¥ç”Ÿæˆå¤±è´¥: {e}", exc_info=True)
            dim = self._get_dimension()
            return [np.random.rand(dim).astype(np.float32) for _ in texts]

    async def _generate_batch_with_api(self, texts: list[str]) -> list[np.ndarray] | None:
        """ä½¿ç”¨ API æ‰¹é‡ç”Ÿæˆ"""
        try:
            # å¯¹äºå¤§å¤šæ•° APIï¼Œæ‰¹é‡è°ƒç”¨å°±æ˜¯å¤šæ¬¡å•ç‹¬è°ƒç”¨
            # è¿™é‡Œä¿æŒç®€å•ï¼Œé€ä¸ªè°ƒç”¨
            results = []
            for text in texts:
                embedding = await self._generate_with_api(text)
                if embedding is None:
                    return None  # å¦‚æœä»»ä½•ä¸€ä¸ªå¤±è´¥ï¼Œè¿”å› None è§¦å‘å›é€€
                results.append(embedding)
            return results
        except Exception as e:
            logger.debug(f"API æ‰¹é‡ç”Ÿæˆå¤±è´¥: {e}")
            return None

    def get_embedding_dimension(self) -> int:
        """è·å–åµŒå…¥å‘é‡ç»´åº¦"""
        return self._get_dimension()


# å…¨å±€å•ä¾‹
_global_generator: EmbeddingGenerator | None = None


def get_embedding_generator(
    use_api: bool = True,
    fallback_model_name: str = "paraphrase-multilingual-MiniLM-L12-v2",
) -> EmbeddingGenerator:
    """
    è·å–å…¨å±€åµŒå…¥ç”Ÿæˆå™¨å•ä¾‹

    Args:
        use_api: æ˜¯å¦ä¼˜å…ˆä½¿ç”¨ API
        fallback_model_name: å›é€€æœ¬åœ°æ¨¡å‹åç§°

    Returns:
        EmbeddingGenerator å®ä¾‹
    """
    global _global_generator
    if _global_generator is None:
        _global_generator = EmbeddingGenerator(
            use_api=use_api,
            fallback_model_name=fallback_model_name
        )
    return _global_generator
